{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXQzH0nC5JtP"
      },
      "source": [
        "# **Project: Amazon Product Recommendation System**\n",
        "\n",
        "# **Marks: 60**\n",
        "\n",
        "\n",
        "Welcome to the project on Recommendation Systems. We will work with the Amazon product reviews dataset for this project. The dataset contains ratings of different electronic products. It does not include information about the products or reviews to avoid bias while building the model.\n",
        "\n",
        "--------------\n",
        "## **Context:**\n",
        "--------------\n",
        "\n",
        "Today, information is growing exponentially with volume, velocity and variety throughout the globe. This has lead to information overload, and too many choices for the consumer of any business. It represents a real dilemma for these consumers and they often turn to denial. Recommender Systems are one of the best tools that help recommending products to consumers while they are browsing online. Providing personalized recommendations which is most relevant for the user is what's most likely to keep them engaged and help business.\n",
        "\n",
        "E-commerce websites like Amazon, Walmart, Target and Etsy use different recommendation models to provide personalized suggestions to different users. These companies spend millions of dollars to come up with algorithmic techniques that can provide personalized recommendations to their users.\n",
        "\n",
        "Amazon, for example, is well-known for its accurate selection of recommendations in its online site. Amazon's recommendation system is capable of intelligently analyzing and predicting customers' shopping preferences in order to offer them a list of recommended products. Amazon's recommendation algorithm is therefore a key element in using AI to improve the personalization of its website. For example, one of the baseline recommendation models that Amazon uses is item-to-item collaborative filtering, which scales to massive data sets and produces high-quality recommendations in real-time.\n",
        "\n",
        "----------------\n",
        "## **Objective:**\n",
        "----------------\n",
        "\n",
        "You are a Data Science Manager at Amazon, and have been given the task of building a recommendation system to recommend products to customers based on their previous ratings for other products. You have a collection of labeled data of Amazon reviews of products. The goal is to extract meaningful insights from the data and build a recommendation system that helps in recommending products to online consumers.\n",
        "\n",
        "-----------------------------\n",
        "## **Dataset:**\n",
        "-----------------------------\n",
        "\n",
        "The Amazon dataset contains the following attributes:\n",
        "\n",
        "- **userId:** Every user identified with a unique id\n",
        "- **productId:** Every product identified with a unique id\n",
        "- **Rating:** The rating of the corresponding product by the corresponding user\n",
        "- **timestamp:** Time of the rating. We **will not use this column** to solve the current problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmdPxJ2Q7W7p"
      },
      "source": [
        "**Note:** The code has some user defined functions that will be usefull while making recommendations and measure model performance, you can use these functions or can create your own functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoRfgjS2yekq"
      },
      "source": [
        "Sometimes, the installation of the surprise library, which is used to build recommendation systems, faces issues in Jupyter. To avoid any issues, it is advised to use **Google Colab** for this project.\n",
        "\n",
        "Let's start by mounting the Google drive on Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GZ0YAszcT4zK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b0041f-d2e7-46b5-eb11-99d131322e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ibk07-Cyekt"
      },
      "source": [
        "**Installing surprise library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "05HQoiZYlsbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994aded8-e926-46ff-eca4-dadc44247b0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise->surprise) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise->surprise) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-surprise->surprise) (1.16.2)\n",
            "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp312-cp312-linux_x86_64.whl size=2611306 sha256=e90d1efade8fc904506139a5cfa8f6b9301129221df84c018a9aacac0b0f297a\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/fa/bc/739bc2cb1fbaab6061854e6cfbb81a0ae52c92a502a7fa454b\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install surprise #installing the surprise library,\n",
        "#this was a big blank when I loaded the file"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** : After running the Below cell, a pop-up will appear prompting you to restart the session. Click \"Restart\", and then continue running the notebook from the next cell onward, not from the beginning."
      ],
      "metadata": {
        "id": "WRDFiuDLXDep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.0"
      ],
      "metadata": {
        "id": "WkEbsBwgySw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7145f5c-936b-486d-b117-52ff665812dc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.0 in /usr/local/lib/python3.12/dist-packages (1.26.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fIt4jcFIm76"
      },
      "source": [
        "## **Importing the necessary libraries and overview of the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jzu2P-TT5JtP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b3e08f2-7e88-4650-bfcb-dd4616e3593b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nObserved building a complete loop for model training,\\nimplementation, graphical analysis\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#importing pandas for loading and data manipulation\n",
        "import pandas as pd\n",
        "\n",
        "#to adapt item-to-item filtering via SVD\n",
        "from surprise import Dataset, Reader, SVD\n",
        "\n",
        "#splitting our data into train and test sets\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "#for evaluating our model performance and complete the loop\n",
        "from surprise import accuracy\n",
        "\n",
        "#Import matplotlib for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "'''\n",
        "Observed building a complete loop for model training,\n",
        "implementation, graphical analysis\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrXYJAv95JtP"
      },
      "source": [
        "### **Loading the data**\n",
        "- Import the Dataset\n",
        "- Add column names ['user_id', 'prod_id', 'rating', 'timestamp']\n",
        "- Drop the column timestamp\n",
        "- Copy the data to another DataFrame called **df**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JGb-Hk1B5JtP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9014450-6cb3-49f0-b2dc-ca3f6786b789"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nObserved dataset imported from mounted drive, assigning/adding column names,\\nremove axis 1 timestamp, and copy to df for best practice\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#1+2 #import the dataset, indent #assign column names as prescribed\n",
        "data = pd.read_csv('/content/drive/My Drive/Python Course/ratings_Electronics.csv',\n",
        "                   names=['user_id', 'prod_id', 'rating', 'timestamp'])\n",
        "\n",
        "#3 #dropping our timestamp column, columns axis 1\n",
        "data = data.drop('timestamp', axis=1)\n",
        "\n",
        "#4 #set our DataFrame to be named df and copy the data to it\n",
        "df = data.copy()\n",
        "\n",
        "'''\n",
        "Observed dataset imported from mounted drive, assigning/adding column names,\n",
        "remove axis 1 timestamp, and copy to df for best practice\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVQnSG5g_9uX"
      },
      "source": [
        "**As this dataset is very large and has 7,824,482 observations, it is not computationally possible to build a model using this. Moreover, many users have only rated a few products and also some products are rated by very few users. Hence, we can reduce the dataset by considering certain logical assumptions.**\n",
        "\n",
        "Here, we will be taking users who have given at least 50 ratings, and the products that have at least 5 ratings, as when we shop online we prefer to have some number of ratings of a product."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4yt9W7Q32EQQ"
      },
      "outputs": [],
      "source": [
        "# Get the column containing the users\n",
        "users = df.user_id\n",
        "\n",
        "# Create a dictionary from users to their number of ratings\n",
        "ratings_count = dict()\n",
        "\n",
        "for user in users:\n",
        "\n",
        "    # If we already have the user, just add 1 to their rating count\n",
        "    if user in ratings_count:\n",
        "        ratings_count[user] += 1\n",
        "\n",
        "    # Otherwise, set their rating count to 1\n",
        "    else:\n",
        "        ratings_count[user] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "19XB60dq2EQR"
      },
      "outputs": [],
      "source": [
        "# We want our users to have at least 50 ratings to be considered\n",
        "RATINGS_CUTOFF = 50\n",
        "\n",
        "remove_users = []\n",
        "\n",
        "for user, num_ratings in ratings_count.items():\n",
        "    if num_ratings < RATINGS_CUTOFF:\n",
        "        remove_users.append(user)\n",
        "\n",
        "df = df.loc[ ~ df.user_id.isin(remove_users)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "33UzK1D82EQS"
      },
      "outputs": [],
      "source": [
        "# Get the column containing the products\n",
        "prods = df.prod_id\n",
        "\n",
        "# Create a dictionary from products to their number of ratings\n",
        "ratings_count = dict()\n",
        "\n",
        "for prod in prods:\n",
        "\n",
        "    # If we already have the product, just add 1 to its rating count\n",
        "    if prod in ratings_count:\n",
        "        ratings_count[prod] += 1\n",
        "\n",
        "    # Otherwise, set their rating count to 1\n",
        "    else:\n",
        "        ratings_count[prod] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "u6YE-lUp2EQT"
      },
      "outputs": [],
      "source": [
        "# We want our item to have at least 5 ratings to be considered\n",
        "RATINGS_CUTOFF = 5\n",
        "\n",
        "remove_users = []\n",
        "\n",
        "for user, num_ratings in ratings_count.items():\n",
        "    if num_ratings < RATINGS_CUTOFF:\n",
        "        remove_users.append(user)\n",
        "\n",
        "df_final = df.loc[~ df.prod_id.isin(remove_users)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aL1JZ00o5JtQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f20f7667-b31c-4c06-fbfa-5039b6be2d2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             user_id     prod_id  rating\n",
              "1310  A3LDPF5FMB782Z  1400501466     5.0\n",
              "1322  A1A5KUIIIHFF4U  1400501466     1.0\n",
              "1335  A2XIOXRRYX0KZY  1400501466     3.0\n",
              "1451   AW3LX47IHPFRL  1400501466     5.0\n",
              "1456  A1E3OB6QMBKRYZ  1400501466     1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff00e1fe-db3b-4891-adcf-3680b088167d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>prod_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1310</th>\n",
              "      <td>A3LDPF5FMB782Z</td>\n",
              "      <td>1400501466</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1322</th>\n",
              "      <td>A1A5KUIIIHFF4U</td>\n",
              "      <td>1400501466</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>A2XIOXRRYX0KZY</td>\n",
              "      <td>1400501466</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1451</th>\n",
              "      <td>AW3LX47IHPFRL</td>\n",
              "      <td>1400501466</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>A1E3OB6QMBKRYZ</td>\n",
              "      <td>1400501466</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff00e1fe-db3b-4891-adcf-3680b088167d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff00e1fe-db3b-4891-adcf-3680b088167d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff00e1fe-db3b-4891-adcf-3680b088167d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Print a few rows of the imported dataset\n",
        "df_final.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuPoy_XfxhXZ"
      },
      "source": [
        "## **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0d0bWeG-sVB"
      },
      "source": [
        "### **Shape of the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyBVTRDTyek0"
      },
      "source": [
        "### **Check the number of rows and columns and provide observations.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fJ4eQKaY5JtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59f4adcc-2e63-4c6f-ceaa-a57e3e702ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of df_final: (65290, 3)\n",
            "Number of rows: 65290\n",
            "Number of columns: 3\n",
            "1. Number of unique users: 1540\n",
            "2. Number of unique products: 5689\n",
            "4. Average rating: 4.294807780670853\n",
            "5. Average rating per user: 4.3054621731146945\n",
            "6. Average rating per product: 4.273843850801201\n",
            "8. Average count of rating per product: 11.476533661451924\n"
          ]
        }
      ],
      "source": [
        "# Check the number of rows and columns and provide observations\n",
        "\n",
        "#let's pull from the newly cleaned df_final a set of row and column numbers as\n",
        "# well as total shape with a print statement\n",
        "print(\"Shape of df_final:\", df_final.shape)\n",
        "print(\"Number of rows:\", df_final.shape[0])\n",
        "print(\"Number of columns:\", df_final.shape[1])\n",
        "\n",
        "#let's use our tools and data to garner unique observations instead of guessing\n",
        "\n",
        "#unique users\n",
        "print(\"1. Number of unique users:\", df_final['user_id'].nunique())\n",
        "\n",
        "#unique products\n",
        "print(\"2. Number of unique products:\", df_final['prod_id'].nunique())\n",
        "\n",
        "#let's get a general idea of sentiment with average rating\n",
        "# we can dive into more later\n",
        "print(\"4. Average rating:\", df_final['rating'].mean())\n",
        "\n",
        "#average rating per user will give us an early idea of engagement spread\n",
        "print(\"5. Average rating per user:\", df_final.groupby('user_id')['rating'].mean().mean())\n",
        "\n",
        "#average rating per product will give us an early idea of product spread\n",
        "print(\"6. Average rating per product:\", df_final.groupby('prod_id')['rating'].mean().mean())\n",
        "\n",
        "#average count of rating per product\n",
        "print(\"8. Average count of rating per product:\", df_final.groupby('prod_id')['rating'].count().mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Slp-fgWQ-sVD"
      },
      "source": [
        "**Write your observations here: We have succesffully reduced the data to 3 columns containing user_id, prod_id and rating, we have a total of 65920 observations of whcih there are 1540 unique users - the simple average rating per user is 4.3 which indicates good general product mechanics. The simpele average rating per product is 4.27 which is also fairly high and indicates user satisfaction with the marketplace. The average ratings given per product or average sample size of ratings on a given particular product is 11 which means we can expect on average each product to be reviewed by at least 11 people within this cleaned dataset. We should note that we introduced a bias by cleaning the data the way we did and could likely have expected this result. We removed outlier low number of ratings which are typically negative and skimmed products with less than 5 ratings to manufacture this data array. We could best conclude then that these results only apply to the products and users within the cleaned dataset with the highest level of accuracy.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAMWm0nC-sVF"
      },
      "source": [
        "### **Data types**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SVrgMkye5JtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "342625c7-7de5-4a1e-edd8-c3a78ed80675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Types of df_final Columns:\n",
            "user_id     object\n",
            "prod_id     object\n",
            "rating     float64\n",
            "dtype: object\n",
            "1. Rating value range: 1.0 to 5.0\n"
          ]
        }
      ],
      "source": [
        "# Check Data types and provide observations\n",
        "\n",
        "# Check data types of columns in df_final we indent for clean display and\n",
        "# print for ease of access to results\n",
        "print(\"Data Types of df_final Columns:\")\n",
        "print(df_final.dtypes)\n",
        "\n",
        "#let's confirm the value range within the float type\n",
        "print(\"1. Rating value range:\", df_final['rating'].min(), \"to\", df_final['rating'].max())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4fOE02D-sVF"
      },
      "source": [
        "**Write your observations here: user_id and prod_id are objects as expected, we know they are encoded as alphanumeric strings from the head read earlier. We confirmed that the ratings value is a float to 1 decimal place between 1.0 to 5.0. We checked for a total integer value of missing values and then misisng values by column and found that there are none missing.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTMpOROT-sVG"
      },
      "source": [
        "### **Checking for missing values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vt-VEjMA5JtQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bda6f428-47a1-4fab-e06f-14239378e2a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2. Missing values:\n",
            " user_id    0\n",
            "prod_id    0\n",
            "rating     0\n",
            "dtype: int64\n",
            "Missing Values by Column in df_final:\n",
            "user_id    0\n",
            "prod_id    0\n",
            "rating     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#let's check for any missing values\n",
        "print(\"2. Missing values:\\n\", df_final.isnull().sum())\n",
        "\n",
        "#and let's break that down by column too\n",
        "print(\"Missing Values by Column in df_final:\")\n",
        "print(df_final.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMWuBNhI5JtR"
      },
      "source": [
        "**Write your observations here: We checked for a total integer value of missing values and then misisng values by column and found that there are none missing.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wETrCg48-sVG"
      },
      "source": [
        "### **Summary Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tYm30MXR5JtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ab6279-8c72-4bd8-b122-1ca21f24f4db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary Statistics of 'rating' in df_final:\n",
            "count    65290.000000\n",
            "mean         4.294808\n",
            "std          0.988915\n",
            "min          1.000000\n",
            "25%          4.000000\n",
            "50%          5.000000\n",
            "75%          5.000000\n",
            "max          5.000000\n",
            "Name: rating, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Summary statistics of 'rating' variable and provide observations\n",
        "\n",
        "# let's use describe to get general summary statistics for the 'rating' variable\n",
        "print(\"Summary Statistics of 'rating' in df_final:\")\n",
        "print(df_final['rating'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqW50EIJxhXc"
      },
      "source": [
        "**Write your observations here: there are 65,290 ratings. The mean rating is 4.29 which is fairly high. The standard deviation is 0.9 which means we can expect that 44,397 observations fall within 3.31 and 5.0 and that this represents 68% of the data. At 2 SDs from the mean this reaches an upperbound more significantly and showcases the skew of the data the range shifts from 2.33 to 5.0 with 95% of the data which intuitively represents the skew we are seeing in our data of amazon ratings.\n",
        "\n",
        "This is a good demonstration of elective bias in ratings especially as we trimmed low rating bomb users or it could be a very highly rated dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywyFrZIf5JtR"
      },
      "source": [
        "### **Checking the rating distribution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QbqhbEVe-sVH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "729599ec-848f-409c-8fea-daf26c4f6e73"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create the bar plot and provide observations\n",
        "\n",
        "# let's reconfirm rating counts\n",
        "rating_counts = df_final['rating'].value_counts().sort_index()\n",
        "\n",
        "# let's create a bar plot to show this cleanly\n",
        "plt.figure(figsize=(5, 5))\n",
        "rating_counts.plot(kind='bar', color='red')\n",
        "plt.title('Distribution of Ratings in df_final')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Number of Ratings')\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0jONrQv-sVH"
      },
      "source": [
        "**Write your observations here: as expected from our hypothesized shape based on our summary statistics! we have a huge skew towards 5.0 - again as we trimmed out elective negative bias earlier this is likely to be expected!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HefpLdLJxhXd"
      },
      "source": [
        "### **Checking the number of unique users and items in the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NbSom7195JtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb975740-e363-43f6-b5f8-c517b0c00c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of rows in df_final: 65290\n",
            "1. Number of unique users: 1540\n",
            "2. Number of unique products: 5689\n"
          ]
        }
      ],
      "source": [
        "# Number of total rows in the data and number of unique user id and product id\n",
        "# in the data\n",
        "\n",
        "#Total rows with a print statement using a definition to store it just in case\n",
        "total_rows = df_final.shape[0]\n",
        "print(\"Total number of rows in df_final:\", total_rows)\n",
        "\n",
        "#For uniques I already did this earlier so let me drag the code lines down and\n",
        "#confirm a print statement\n",
        "print(\"1. Number of unique users:\", df_final['user_id'].nunique())\n",
        "print(\"2. Number of unique products:\", df_final['prod_id'].nunique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwgz6CUt-sVI"
      },
      "source": [
        "**Write your observations here: we have 65,290 rows with a total of 1540 unique users and 5689 unique products, the ratio of unique products per user is 3 discrete whole number products per user with an actual value of 3.69**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfDnhSS4-sVI"
      },
      "source": [
        "### **Users with the most number of ratings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "n7MX452q5JtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a44de404-027e-47de-d322-2184b766c3de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Users by Number of Ratings:\n",
            "user_id\n",
            "ADLVFFE4VBT8      295\n",
            "A3OXHLG6DIBRW8    230\n",
            "A1ODOGXEYECQQ8    217\n",
            "A36K2N527TXXJN    212\n",
            "A25C2M3QF9G7OQ    203\n",
            "A680RUE1FDO8B     196\n",
            "A1UQBFCERIP7VJ    193\n",
            "A22CW0ZHY3NJH8    193\n",
            "AWPODHOB4GFWL     184\n",
            "AGVWTYW0ULXHT     179\n",
            "Name: count, dtype: int64\n",
            "Percentile rank for a rating count of 179: 99.42%\n",
            "Percentile rank for a rating count of 295: 100.00%\n"
          ]
        }
      ],
      "source": [
        "# Top 10 users based on the number of ratings\n",
        "\n",
        "#let's store a compute var of user rating counts to sort and parse by, we can\n",
        "# use this in future iterations then too\n",
        "user_rating_counts = df_final['user_id'].value_counts()\n",
        "\n",
        "#let's follow the same variable storing methodology here for this specific query\n",
        "# although there are multiple routes to do this\n",
        "top_10_users = user_rating_counts.head(10)\n",
        "\n",
        "#let's clean it out in a print statement\n",
        "print(\"Top 10 Users by Number of Ratings:\")\n",
        "print(top_10_users)\n",
        "\n",
        "#what are these as percentile expressions of the overall data so we can compare\n",
        "#and measure them\n",
        "#let's set a variable for each rating count we pulled from the high end of\n",
        "# rank #1 and rank #10, #1 will serve as a code validator\n",
        "rating_count_179 = 179\n",
        "rating_count_295 = 295\n",
        "\n",
        "#then let's generate a percentile rank percentage of users with rating counts\n",
        "# <= the given value\n",
        "percentile_179 = (user_rating_counts <= rating_count_179).mean() * 100\n",
        "percentile_295 = (user_rating_counts <= rating_count_295).mean() * 100\n",
        "\n",
        "#finally let's print those results too\n",
        "print(f\"Percentile rank for a rating count of {rating_count_179}: {percentile_179:.2f}%\")\n",
        "print(f\"Percentile rank for a rating count of {rating_count_295}: {percentile_295:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X2w_jt9-sVI"
      },
      "source": [
        "**Write your observations here: the highest number of individual user ratings is 295 for user hash ADLVFFE4VBT8 and the lowest is 179 for user hash AGVWTYW0ULXHT giving a top 10 range of 116 review difference between #1 and #10 - this is relatively high as I believe i've reviewed roughly 10 restauraunts and 4 products in my life.\n",
        "\n",
        "To deepen the relation to the data we calculate the percentile ranks of #1 and #10 to confirm our data and understand how much population #10 represents, which was the top 99.42%.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnYTx-Ol-sVg"
      },
      "source": [
        "**Now that we have explored and prepared the data, let's build the first recommendation system.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xYGrGVy5JtS"
      },
      "source": [
        "## **Model 1: Rank Based Recommendation System**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yxZTj1UPxhXh",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "920eea2f-b78f-499a-c909-d23f7fe2ae53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First five records of final_rating DataFrame:\n",
            "         prod_id  average_rating  rating_count\n",
            "5688  B00LGQ6HL8             5.0             5\n",
            "2302  B003DZJQQI             5.0            14\n",
            "3443  B005FDXF2C             5.0             7\n",
            "5554  B00I6CVPVC             5.0             7\n",
            "4810  B00B9KOCYA             5.0             8\n"
          ]
        }
      ],
      "source": [
        "# Calculate the average rating for each product\n",
        "# Calculate the count of ratings for each product\n",
        "product_stats = df_final.groupby('prod_id').agg(\n",
        "    #group our dataframe by prod_id and aggregate the index\n",
        "    average_rating=('rating', 'mean'),\n",
        "    #include average rating as a mean\n",
        "    rating_count=('rating', 'count')\n",
        "    #include rating count as a count\n",
        ").reset_index()#our current index is prod_id so let's reset that and convert\n",
        "                #it back to a standard column\n",
        "\n",
        "# Create a dataframe with calculated average and count of ratings\n",
        "#set dataframe\n",
        "final_rating = product_stats.copy()\n",
        "\n",
        "# Sort the dataframe by average of ratings in the descending order\n",
        "final_rating = final_rating.sort_values(by='average_rating', ascending=False)\n",
        "#desecending == ascending false, value sort by our average_rating var\n",
        "\n",
        "# See the first five records of the \"final_rating\" dataset\n",
        "#let's use a clean print statement now that it is parsed, columnized, framed and\n",
        "#descended\n",
        "print(\"First five records of final_rating DataFrame:\")\n",
        "print(final_rating.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zKU__5s1xhXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0560b61-67e2-4d96-b81b-c23b09f1ca57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Products with exactly 5 interactions:\n",
            "         prod_id  average_rating  rating_count\n",
            "2     1400599997             4.0             5\n",
            "4     B00000DM9W             5.0             5\n",
            "8     B00000K135             4.8             5\n",
            "9     B00000K4KH             5.0             5\n",
            "16    B000021YU8             4.6             5\n",
            "...          ...             ...           ...\n",
            "5666  B00JZAB8OI             4.8             5\n",
            "5674  B00KHA5G6G             4.4             5\n",
            "5680  B00KONCDVM             4.0             5\n",
            "5682  B00KXAFYZS             5.0             5\n",
            "5688  B00LGQ6HL8             5.0             5\n",
            "\n",
            "[1082 rows x 3 columns]\n",
            "\n",
            "Top 10 products by average rating (min 5 interactions):\n",
            "         prod_id  average_rating  rating_count\n",
            "5688  B00LGQ6HL8             5.0             5\n",
            "2302  B003DZJQQI             5.0            14\n",
            "3443  B005FDXF2C             5.0             7\n",
            "5554  B00I6CVPVC             5.0             7\n",
            "4810  B00B9KOCYA             5.0             8\n",
            "2286  B003CK10DG             5.0             5\n",
            "2266  B003B41XYO             5.0             5\n",
            "433   B0007WK8KS             5.0             6\n",
            "4194  B0084FM5JC             5.0             5\n",
            "3467  B005GI2VMG             5.0            10\n"
          ]
        }
      ],
      "source": [
        "# Defining a function to get the top n products based on the highest average\n",
        "# rating and minimum interactions\n",
        "def get_top_n_products(df, n, min_interactions=5): #set to 5\n",
        "    \"\"\"\n",
        "    Top n products, from highest average rating, with min num of interactions\n",
        "    -df (DataFrame), n (int) # of products, min_interactions # of minimum ratings for a product (int)\n",
        "    \"\"\"\n",
        "    # let's import our above groupby parameters to define this (indented)\n",
        "    product_stats = df.groupby('prod_id').agg(\n",
        "        average_rating=('rating', 'mean'),\n",
        "        rating_count=('rating', 'count')\n",
        "    ).reset_index()\n",
        "\n",
        "# Finding products with minimum number of interactions\n",
        "# We will use filter\n",
        "    filtered_products = product_stats[product_stats['rating_count'] >= min_interactions]\n",
        "    # note the indent we are going to define all of this in the function loop\n",
        "\n",
        "# Sorting values with respect to average rating\n",
        "# let's define a top_n to return and sort average rating in a descending manner,\n",
        "# let's top that off with a head and return to see our work\n",
        "    top_n = filtered_products.sort_values(by='average_rating', ascending=False).head(n)\n",
        "    return top_n\n",
        "     # note the indent we are going to define all of this in the function loop\n",
        "\n",
        "# Find products with exactly 5 interactions\n",
        "# let's see how many are right on the cusp by relatively the same interaction at\n",
        "# the value point 5\n",
        "min_interaction_products = df_final.groupby('prod_id').agg(\n",
        "    average_rating=('rating', 'mean'),\n",
        "    rating_count=('rating', 'count')\n",
        ").reset_index()\n",
        "min_interaction_products = min_interaction_products[min_interaction_products['rating_count'] == 5]\n",
        "\n",
        "# let's cleanly print the results\n",
        "print(\"Products with exactly 5 interactions:\")\n",
        "print(min_interaction_products[['prod_id', 'average_rating', 'rating_count']])\n",
        "print(\"\\nTop 10 products by average rating (min 5 interactions):\")\n",
        "print(get_top_n_products(df_final, 10, 5)[['prod_id', 'average_rating', 'rating_count']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8l6373PxhXi"
      },
      "source": [
        "### **Recommending top 5 products with 50 minimum interactions based on popularity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dBxdLiM_xhXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdca5e10-3ba4-4316-a90a-455d66068bfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 products by popularity (min 50 interactions):\n",
            "         prod_id  average_rating  rating_count\n",
            "4218  B0088CJT4U        4.218447           206\n",
            "2316  B003ES5ZUU        4.864130           184\n",
            "781   B000N99BBC        4.772455           167\n",
            "4126  B007WTAJTO        4.701220           164\n",
            "4180  B00829TIEK        4.436242           149\n"
          ]
        }
      ],
      "source": [
        "#let's modify the above function to meet the current parameters\n",
        "#let's define a specific although lengthy var name with these pieces\n",
        "#top 5 products, top_n of 5, and min interaction of 50\n",
        "def get_top_n_products_by_popularity(df, n, min_interactions=50):\n",
        "#note we know definitionally above how this function tends to operate\n",
        "    product_stats = df.groupby('prod_id').agg(\n",
        "        average_rating=('rating', 'mean'),\n",
        "        rating_count=('rating', 'count')\n",
        "    ).reset_index()\n",
        "\n",
        "# Finding products with minimum number of interactions\n",
        "# We will use filter\n",
        "    filtered_products = product_stats[product_stats['rating_count'] >= min_interactions]\n",
        "\n",
        "# Sorting values\n",
        "# let's define a top_n to return and sort in a descending manner,\n",
        "# let's top that off with a head and return to see our work\n",
        "    top_n = filtered_products.sort_values(by='rating_count', ascending=False).head(n)\n",
        "    return top_n\n",
        "    # note the indent we are going to define all of this in the function loop\n",
        "\n",
        "#let's call and define this new top 5\n",
        "top_5_products = get_top_n_products_by_popularity(df_final, 5, 50)\n",
        "\n",
        "#let's clean all that out witha  print statement\n",
        "print(\"Top 5 products by popularity (min 50 interactions):\")\n",
        "print(top_5_products[['prod_id', 'average_rating', 'rating_count']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9_xW_UMxhXj"
      },
      "source": [
        "### **Recommending top 5 products with 100 minimum interactions based on popularity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dZgGZCUoxhXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "354fe13a-bc61-4322-d4b0-cf5b67765d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 products by popularity (min 100 interactions):\n",
            "         prod_id  average_rating  rating_count\n",
            "4218  B0088CJT4U        4.218447           206\n",
            "2316  B003ES5ZUU        4.864130           184\n",
            "781   B000N99BBC        4.772455           167\n",
            "4126  B007WTAJTO        4.701220           164\n",
            "4180  B00829TIEK        4.436242           149\n"
          ]
        }
      ],
      "source": [
        "#let's modify the above function to meet the current parameters\n",
        "#let's define a specific although lengthy var name with these pieces\n",
        "#top 5 products, top_n of 5, and min interaction of 100 this time\n",
        "def get_top_n_products_by_popularity(df, n, min_interactions=100):\n",
        "#just change min_interactions to = 100\n",
        "#note we know definitionally above how this function tends to operate\n",
        "    product_stats = df.groupby('prod_id').agg(\n",
        "        average_rating=('rating', 'mean'),\n",
        "        rating_count=('rating', 'count')\n",
        "    ).reset_index()\n",
        "\n",
        "# Finding products with minimum number of interactions\n",
        "# We will use filter\n",
        "    filtered_products = product_stats[product_stats['rating_count'] >= min_interactions]\n",
        "\n",
        "# Sorting values\n",
        "# let's define a top_n to return and sort in a descending manner,\n",
        "# let's top that off with a head and return to see our work\n",
        "    top_n = filtered_products.sort_values(by='rating_count', ascending=False).head(n)\n",
        "    return top_n\n",
        "    # note the indent we are going to define all of this in the function loop\n",
        "\n",
        "#let's call and define this new top 5\n",
        "top_5_products = get_top_n_products_by_popularity(df_final, 5, 50)\n",
        "\n",
        "#let's clean all that out witha  print statement\n",
        "print(\"Top 5 products by popularity (min 100 interactions):\")\n",
        "print(top_5_products[['prod_id', 'average_rating', 'rating_count']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL-m68a15JtT",
        "outputId": "69132b0f-8d3f-4798-f6a0-249e17a3c822"
      },
      "source": [
        "We have recommended the **top 5** products by using the popularity recommendation system. Now, let's build a recommendation system using **collaborative filtering.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJI5kiiGvOOK"
      },
      "source": [
        "## **Model 2: Collaborative Filtering Recommendation System**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skzc0N1_nVNB"
      },
      "source": [
        "### **Building a baseline user-user similarity based recommendation system**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Uo_MYMnVNB"
      },
      "source": [
        "- Below, we are building **similarity-based recommendation systems** using `cosine` similarity and using **KNN to find similar users** which are the nearest neighbor to the given user.  \n",
        "- We will be using a new library, called `surprise`, to build the remaining models. Let's first import the necessary classes and functions from this library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UJ1wEylUpexj"
      },
      "outputs": [],
      "source": [
        "# To compute the accuracy of models\n",
        "from surprise import accuracy\n",
        "\n",
        "# Class is used to parse a file containing ratings, data should be in structure - user ; item ; rating\n",
        "from surprise.reader import Reader\n",
        "\n",
        "# Class for loading datasets\n",
        "from surprise.dataset import Dataset\n",
        "\n",
        "# For tuning model hyperparameters\n",
        "from surprise.model_selection import GridSearchCV\n",
        "\n",
        "# For splitting the rating data in train and test datasets\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# For implementing similarity-based recommendation system\n",
        "from surprise.prediction_algorithms.knns import KNNBasic\n",
        "\n",
        "# For implementing matrix factorization based recommendation system\n",
        "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
        "\n",
        "# for implementing K-Fold cross-validation\n",
        "from surprise.model_selection import KFold\n",
        "\n",
        "# For implementing clustering-based recommendation system\n",
        "from surprise import CoClustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54MqVAtDTsnl"
      },
      "source": [
        "**Before building the recommendation systems, let's  go over some basic terminologies we are going to use:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsxb3xhnTsnl"
      },
      "source": [
        "**Relevant item:** An item (product in this case) that is actually **rated higher than the threshold rating** is relevant, if the **actual rating is below the threshold then it is a non-relevant item**.  \n",
        "\n",
        "**Recommended item:** An item that's **predicted rating is higher than the threshold is a recommended item**, if the **predicted rating is below the threshold then that product will not be recommended to the user**.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moyLUHCuTsnl"
      },
      "source": [
        "**False Negative (FN):** It is the **frequency of relevant items that are not recommended to the user**. If the relevant items are not recommended to the user, then the user might not buy the product/item. This would result in the **loss of opportunity for the service provider**, which they would like to minimize.\n",
        "\n",
        "**False Positive (FP):** It is the **frequency of recommended items that are actually not relevant**. In this case, the recommendation system is not doing a good job of finding and recommending the relevant items to the user. This would result in **loss of resources for the service provider**, which they would also like to minimize."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yuvc2VaZTsnl"
      },
      "source": [
        "**Recall:** It is the **fraction of actually relevant items that are recommended to the user**, i.e., if out of 10 relevant products, 6 are recommended to the user then recall is 0.60. Higher the value of recall better is the model. It is one of the metrics to do the performance assessment of classification models.\n",
        "\n",
        "**Precision:** It is the **fraction of recommended items that are relevant actually**, i.e., if out of 10 recommended items, 6 are found relevant by the user then precision is 0.60. The higher the value of precision better is the model. It is one of the metrics to do the performance assessment of classification models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NLc36Y8Tsnm"
      },
      "source": [
        "**While making a recommendation system, it becomes customary to look at the performance of the model. In terms of how many recommendations are relevant and vice-versa, below are some most used performance metrics used in the assessment of recommendation systems.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqF8fRBqTsnm"
      },
      "source": [
        "### **Precision@k, Recall@ k, and F1-score@k**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imMJNF0HTsnm"
      },
      "source": [
        "**Precision@k** - It is the **fraction of recommended items that are relevant in `top k` predictions**. The value of k is the number of recommendations to be provided to the user. One can choose a variable number of recommendations to be given to a unique user.  \n",
        "\n",
        "\n",
        "**Recall@k** - It is the **fraction of relevant items that are recommended to the user in `top k` predictions**.\n",
        "\n",
        "**F1-score@k** - It is the **harmonic mean of Precision@k and Recall@k**. When **precision@k and recall@k both seem to be important** then it is useful to use this metric because it is representative of both of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBW4BUhWTsnm"
      },
      "source": [
        "### **Some useful functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOBHKh0eTsnm"
      },
      "source": [
        "- Below function takes the **recommendation model** as input and gives the **precision@k, recall@k, and F1-score@k** for that model.  \n",
        "- To compute **precision and recall**, **top k** predictions are taken under consideration for each user.\n",
        "- We will use the precision and recall to compute the F1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Rxn-GahOTsnm"
      },
      "outputs": [],
      "source": [
        "def precision_recall_at_k(model, k = 10, threshold = 3.5):\n",
        "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
        "\n",
        "    # First map the predictions to each user\n",
        "    user_est_true = defaultdict(list)\n",
        "\n",
        "    # Making predictions on the test data\n",
        "    predictions = model.test(testset)\n",
        "\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "\n",
        "        # Sort user ratings by estimated value\n",
        "        user_ratings.sort(key = lambda x: x[0], reverse = True)\n",
        "\n",
        "        # Number of relevant items\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "\n",
        "        # Number of recommended items in top k\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "\n",
        "        # Number of relevant and recommended items in top k\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
        "                              for (est, true_r) in user_ratings[:k])\n",
        "\n",
        "        # Precision@K: Proportion of recommended items that are relevant\n",
        "        # When n_rec_k is 0, Precision is undefined. Therefore, we are setting Precision to 0 when n_rec_k is 0\n",
        "\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "\n",
        "        # Recall@K: Proportion of relevant items that are recommended\n",
        "        # When n_rel is 0, Recall is undefined. Therefore, we are setting Recall to 0 when n_rel is 0\n",
        "\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
        "\n",
        "    # Mean of all the predicted precisions are calculated.\n",
        "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
        "\n",
        "    # Mean of all the predicted recalls are calculated.\n",
        "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
        "\n",
        "    accuracy.rmse(predictions)\n",
        "\n",
        "    print('Precision: ', precision) # Command to print the overall precision\n",
        "\n",
        "    print('Recall: ', recall) # Command to print the overall recall\n",
        "\n",
        "    print('F_1 score: ', round((2*precision*recall)/(precision+recall), 3)) # Formula to compute the F-1 score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZmsamDVyek-"
      },
      "source": [
        "**Hints:**\n",
        "\n",
        "- To compute **precision and recall**, a **threshold of 3.5 and k value of 10 can be considered for the recommended and relevant ratings**.\n",
        "- Think about the performance metric to choose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hxjJMTwnVNB"
      },
      "source": [
        "Below we are loading the **`rating` dataset**, which is a **pandas DataFrame**, into a **different format called `surprise.dataset.DatasetAutoFolds`**, which is required by this library. To do this, we will be **using the classes `Reader` and `Dataset`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rGfYDiOCpe4X"
      },
      "outputs": [],
      "source": [
        "#imports check for my own flow\n",
        "from surprise import Reader, Dataset\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# Instantiating Reader scale with expected rating scale\n",
        "# set our scale although it is float we have only seen whole integers per obser\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Loading the rating dataset\n",
        "# set our data load from our final dataframe based on the columns we assigned\n",
        "data = Dataset.load_from_df(df_final[['user_id', 'prod_id', 'rating']], reader)\n",
        "\n",
        "# Splitting the data into train and test datasets\n",
        "# use trainset and testset to control the proportion of training and testing data size,\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "#reproducibility state set, 80/20 train-test split for KNN which provides\n",
        "#RMSE, Precision@10, Recall@10, Threshhold 3.5 as required"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmHTEt7TnVNC"
      },
      "source": [
        "Now, we are **ready to build the first baseline similarity-based recommendation system** using the cosine similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVDfVHB4tQfU"
      },
      "source": [
        "### **Building the user-user Similarity-based Recommendation System**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vO3FL7iape8A",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51b2d301-7c02-44ba-f973-460e7da48ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision:  0.855\n",
            "Recall:  0.858\n",
            "F_1 score:  0.856\n"
          ]
        }
      ],
      "source": [
        "#check imports\n",
        "from surprise import KNNBasic\n",
        "from collections import defaultdict\n",
        "\n",
        "# Declaring the similarity options\n",
        "sim_options = {\n",
        "    'name': 'cosine',\n",
        "    'user_based': True\n",
        "}\n",
        "# we were asked to use cosine and for KNN nearest that is user based\n",
        "\n",
        "\n",
        "# Initialize the KNNBasic model using sim_options declared, Verbose = False, and setting random_state = 1\n",
        "model = KNNBasic(sim_options=sim_options, verbose=False, random_state=1)\n",
        "#KNNBasic model loading our sim options and setting a reproducibility state\n",
        "\n",
        "# Fit the model on the training data\n",
        "model.fit(trainset)\n",
        "\n",
        "# Let us compute precision@k, recall@k, and f_1 score using the precision_recall_at_k function defined above\n",
        "def precision_recall_at_k(model, k=10, threshold=3.5):  #parameters input\n",
        "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
        "    user_est_true = defaultdict(list)  #userlist\n",
        "    predictions = model.test(testset)  #predictions\n",
        "    for uid, _, true_r, est, _ in predictions:  #looping through predictions\n",
        "        user_est_true[uid].append((est, true_r)) #appending to userlist\n",
        "    precisions = dict() #precision dictionary\n",
        "    recalls = dict() #recall dictionary\n",
        "    for uid, user_ratings in user_est_true.items(): #looping through userlist\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True) #sorting user key\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings) #rel\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k]) #k\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))#r/k\n",
        "                              for (est, true_r) in user_ratings[:k]) #for loop\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0 #prc\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0 #recall\n",
        "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
        "    #precision and count\n",
        "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
        "    #recall and count\n",
        "    print('Precision: ', precision) #print result precision\n",
        "    print('Recall: ', recall) #print result recall\n",
        "    print('F_1 score: ', round((2 * precision * recall) / (precision + recall), 3) if (precision + recall) != 0 else 0)\n",
        "    # finally, print f_1 score, rounded\n",
        "\n",
        "precision_recall_at_k(model) #end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEuJK_A9Tsnn"
      },
      "source": [
        "**Write your observations here:\n",
        "Let's analyze these results.\n",
        "\n",
        "Precision of 85.5% indicates that 85.5% of recommendations are precise or worth listening to system suggestion - this is minimized for false positives. This means that our model compares well to standard data.\n",
        "\n",
        "A recall of 85.8% indicates that when testing the model, 85.8% of the relevant top 10 recommendations were items in the real scenario that the user actually rated greater than or equal to 3.5 - this means that our model compares well to real instances.\n",
        "\n",
        "Our F_1 score will show our harmonic mean or the relationship between precision and recall in this situation. If our value was too close to 1 then it would indicate that it trades precision for recall. Here it is relatively high but not 1 so we can state that it is relatively well-balanced with a slight favoring towards precision.\n",
        "\n",
        "Overall it seems to have a high standard of precision and recall that can be fine tuned. This also indicates that within our data environment the model of user-user similarity is a good metric for user analysis in this case. The model is slightly conservative favoring precision.\n",
        "\n",
        "I will note again that we've created a skew based on user satisfaction and not on total data, but this insight is still helpful and even useful for being more specific about those populations when compared to larger total datasets.\n",
        "\n",
        "I am interested to see if the hybridization of this model will lead to better results, I would presume it would.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reFD0-nsnVNC"
      },
      "source": [
        "Let's now **predict rating for a user with `userId=A3LDPF5FMB782Z` and `productId=1400501466`** as shown below. Here the user has already interacted or watched the product with productId '1400501466' and given a rating of 5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Sxd23bZ9pe_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06b7e85-0f42-4d93-bbfa-58dcc0f792c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user A3LDPF5FMB782Z and product 1400501466: 3.40\n",
            "Actual rating: 5\n"
          ]
        }
      ],
      "source": [
        "# Predicting rating for a sample user with an interacted product\n",
        "\n",
        "#let's define based on the params\n",
        "user_id = 'A3LDPF5FMB782Z'\n",
        "prod_id = '1400501466'\n",
        "\n",
        "#let's use the trained KNNBasic model to run the prediction\n",
        "predicted_rating = model.predict(user_id, prod_id)\n",
        "\n",
        "# let's print that clean as the predicted rating and actual rating\n",
        "print(f\"Predicted rating for user {user_id} and product {prod_id}: {predicted_rating.est:.2f}\")\n",
        "print(f\"Actual rating: 5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENJcqG_wemRH"
      },
      "source": [
        "**Write your observations here: Here we have a difference between the predicted rating and the actual rating of 1.6, which is relatively high for this context and a false negative interaction // is relevant but was not recommended. The model severely underestimated the user's preference in this instance. This means, for this specific product, our model struggles to understand user preference. This is likely because we are using KNN nearest neighbors and our model seems to be relatively conservative. This highlights a limitation for this model and type of model when there isn't enough data or binding data between products and users. This could also just arise from a mismatch in preference that can occur with nearest neighbors. The model matrix could have sparsity - few users rating that product. The model may have a cold start issue based on the number of ratings from that particular user so far. The model may meet an unavoidable but always fought nuance of user preference divergence where increasingly unique tastes and niche products leads to poor neighbor represntation under KNN. This implies the model needs to be changed or negative externalities could occur for the business.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj6ecbglTsno"
      },
      "source": [
        "Below is the function to find the **list of users who have not seen the product with product id \"1400501466\"**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "u2hpe2P6W7bM"
      },
      "outputs": [],
      "source": [
        "def n_users_not_interacted_with(n, data, prod_id):\n",
        "    users_interacted_with_product = set(data[data['prod_id'] == prod_id]['user_id'])\n",
        "    all_users = set(data['user_id'])\n",
        "    return list(all_users.difference(users_interacted_with_product))[:n] # where n is the number of elements to get in the list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xCRBMD-RTsno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d06532b-b43f-4197-e28c-a55cfd4c0472"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A2Y3WWPUKIJ59I',\n",
              " 'A38KK0SZYEH5UD',\n",
              " 'A3CW0ZLUO5X2B1',\n",
              " 'A33152QEGO2MZN',\n",
              " 'A233TZONT1OGR0']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Find unique user_id where prod_id is not equal to \"1400501466\"\n",
        "n_users_not_interacted_with(5, df_final, '1400501466')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**:\n",
        "The function **n_users_not_interacted_with** uses Python sets to find users who have not interacted with a specific product. Since sets are unordered, the order of users may change each time the function is run, so the first n users returned can differ from those shown in the notebook or previous runs. This variation is expected and not a mistake. Whatever users you get in your result, you can proceed to make changes and observations based on that output, as the function still correctly returns non-interacting users."
      ],
      "metadata": {
        "id": "2AjQZNhfpzZ7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT42ecaSTsno"
      },
      "source": [
        "* It can be observed from the above list that **user \"A2UOHALGF2X77Q\" has not seen the product with productId \"1400501466\"** as this user id is a part of the above list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXSgq8OEnVNE"
      },
      "source": [
        "**Below we are predicting rating for `userId=A2UOHALGF2X77Q` and `prod_id=1400501466`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "PbFcBj1PpfEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0816022d-0a4e-4e01-a27a-86c2f0084c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted rating for user A2UOHALGF2X77Q and product 1400501466: 4.29\n"
          ]
        }
      ],
      "source": [
        "# Predicting rating for a sample user with a non interacted product\n",
        "\n",
        "#set our user_id and prod_id\n",
        "user_id = 'A2UOHALGF2X77Q'\n",
        "prod_id = '1400501466'\n",
        "\n",
        "#call on KNN Basic model with params input\n",
        "predicted_rating = model.predict(user_id, prod_id)\n",
        "\n",
        "# clean out our assessment in a print statement\n",
        "print(f\"Predicted rating for user {user_id} and product {prod_id}: {predicted_rating.est:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02rwld8yemRI"
      },
      "source": [
        "**Write your observations here: We confirmed the user did not rate the product yet and then found their KNNbasic predictor to be a 5.0 star rating for the given item. We know the model currently underestimates user preference and should do more testing.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejjof6csnVNF"
      },
      "source": [
        "### **Improving similarity-based recommendation system by tuning its hyperparameters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2j4VvfQnVNF"
      },
      "source": [
        "Below, we will be tuning hyperparameters for the `KNNBasic` algorithm. Let's try to understand some of the hyperparameters of the KNNBasic algorithm:\n",
        "\n",
        "- **k** (int) – The (max) number of neighbors to take into account for aggregation. Default is 40.\n",
        "- **min_k** (int) – The minimum number of neighbors to take into account for aggregation. If there are not enough neighbors, the prediction is set to the global mean of all ratings. Default is 1.\n",
        "- **sim_options** (dict) – A dictionary of options for the similarity measure. And there are four similarity measures available in surprise -\n",
        "    - cosine\n",
        "    - msd (default)\n",
        "    - Pearson\n",
        "    - Pearson baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9LmPbSUSTsnp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9140513a-9b58-4bc3-9c75-43dbcdf1a46a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE score: 0.970\n",
            "Best parameters:\n",
            "  k: 60\n",
            "  min_k: 5\n",
            "  sim_options: {'name': 'cosine', 'user_based': True}\n"
          ]
        }
      ],
      "source": [
        "# Setting up parameter grid to tune the hyperparameters\n",
        "#import check\n",
        "from surprise import KNNBasic\n",
        "from surprise.model_selection import GridSearchCV\n",
        "#building parameter grid, using above params and measures\n",
        "param_grid = {\n",
        "    'k': [20, 40, 60],\n",
        "    'min_k': [1, 3, 5],\n",
        "    'sim_options': {\n",
        "        'name': ['cosine', 'msd', 'pearson', 'pearson_baseline'],\n",
        "        'user_based': [True]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Performing 3-fold cross-validation to tune the hyperparameters\n",
        "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
        "\n",
        "# Fitting the data\n",
        "gs.fit(data)\n",
        "\n",
        "# Best RMSE score\n",
        "# Combination of parameters that gave the best RMSE score\n",
        "# We can handle this in one results print interaction\n",
        "print(f\"Best RMSE score: {gs.best_score['rmse']:.3f}\")\n",
        "print(\"Best parameters:\")\n",
        "print(f\"  k: {gs.best_params['rmse']['k']}\")\n",
        "print(f\"  min_k: {gs.best_params['rmse']['min_k']}\")\n",
        "print(f\"  sim_options: {gs.best_params['rmse']['sim_options']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2fHNvu7nVNF"
      },
      "source": [
        "Once the grid search is **complete**, we can get the **optimal values for each of those hyperparameters**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHWgxu_YnVNG"
      },
      "source": [
        "Now, let's build the **final model by using tuned values of the hyperparameters**, which we received by using **grid search cross-validation**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "PujRJA8X_JEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d20b18e-a8c1-48f3-f163-00e85b171ac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision:  0.849\n",
            "Recall:  0.893\n",
            "F_1 score:  0.87\n"
          ]
        }
      ],
      "source": [
        "# Using the optimal similarity measure for user-user based collaborative filtering\n",
        "#let's pull these from our above output\n",
        "sim_options = {'name': 'cosine', 'user_based': True}\n",
        "\n",
        "# Creating an instance of KNNBasic with optimal hyperparameter values\n",
        "# we will pull k, min_k, our sim option term above and set a reproducibility state\n",
        "model = KNNBasic(k=60, min_k=5, sim_options=sim_options, verbose=False, random_state=1)\n",
        "\n",
        "# Training the algorithm on the trainset\n",
        "model.fit(trainset)\n",
        "\n",
        "# Let us compute precision@k and recall@k also with k =10\n",
        "def precision_recall_at_k(model, k=10, threshold=3.5):\n",
        "    \"\"\"\n",
        "    Returns precision and recall at k metrics for each user value input\n",
        "    \"\"\"\n",
        "    user_est_true = defaultdict(list) #userlist\n",
        "    predictions = model.test(testset) #predictionlist\n",
        "    for uid, _, true_r, est, _ in predictions: #prediction loop\n",
        "        user_est_true[uid].append((est, true_r)) #user append\n",
        "    precisions = dict() #prec dict\n",
        "    recalls = dict() #recall dict\n",
        "    for uid, user_ratings in user_est_true.items(): #userloop\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True) #user sort\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings) #nrel\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k]) #k\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) #x2\n",
        "                              for (est, true_r) in user_ratings[:k]) #in user\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0 #if p\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0 #if r\n",
        "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
        "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
        "    # then we print the results\n",
        "    print('Precision: ', precision)\n",
        "    print('Recall: ', recall)\n",
        "    print('F_1 score: ', round((2 * precision * recall) / (precision + recall), 3) if (precision + recall) != 0 else 0)\n",
        "\n",
        "# finally call the model for evaluation\n",
        "precision_recall_at_k(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHsWvFjKTsnp"
      },
      "source": [
        "**Write your observations here: After tuning with hyperparameters we observe that we have traded an increase in recall for a very small decrease in precision. This means that products for our previous user are less likely to be missed but that some more irrelevant items may get recommended. Our F_1 score also improved between recall and precision showing that we have further balanced accuracy and completeness with this change. It is also worth noting that the RMSE itself was at a solid level.\n",
        "\n",
        "Including more neighbors to 60 gave us a better grasp of user preference. Increasing the minimum neighbors to 5 also decreased the reliance on global or total stats for new or under-reviewed products. **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhcAXK0CnVNG"
      },
      "source": [
        "### **Steps:**\n",
        "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
        "- **Predict rating for `userId=\"A2UOHALGF2X77Q\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
        "- **Compare the output with the output from the baseline model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "FgV63lHiq1TV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06cb83b3-a36d-4459-da29-4dc837462955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline model - Predicted rating for user A3LDPF5FMB782Z and prod_id 1400501466: 3.40\n",
            "Optimized model - Predicted rating for user A3LDPF5FMB782Z and prod_id 1400501466: 3.40\n",
            "Actual rating: 5\n"
          ]
        }
      ],
      "source": [
        "# Use sim_user_user_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId 1400501466\n",
        "\n",
        "# Re-train baseline model\n",
        "baseline_sim_options = {'name': 'cosine', 'user_based': True}\n",
        "baseline_model = KNNBasic(k=40, min_k=1, sim_options=baseline_sim_options, verbose=False, random_state=1)\n",
        "baseline_model.fit(trainset)\n",
        "\n",
        "# set user and prod ID\n",
        "user_id = 'A3LDPF5FMB782Z'\n",
        "prod_id = '1400501466'\n",
        "\n",
        "# Use the optimized KNNBasic model\n",
        "optimized_pred = model.predict(user_id, prod_id)\n",
        "\n",
        "# Baseline model prediction\n",
        "baseline_pred = baseline_model.predict(user_id, prod_id)\n",
        "\n",
        "#Print compare\n",
        "print(f\"Baseline model - Predicted rating for user {user_id} and prod_id {prod_id}: {baseline_pred.est:.2f}\")\n",
        "print(f\"Optimized model - Predicted rating for user {user_id} and prod_id {prod_id}: {optimized_pred.est:.2f}\")\n",
        "print(f\"Actual rating: 5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "HXO2Ztjhq1bN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a718eded-ddb7-4f1e-8dad-4ddba0e092cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline model - Predicted rating for user A2UOHALGF2X77Q and prod_id 1400501466: 5.00\n",
            "Optimized model - Predicted rating for user A2UOHALGF2X77Q and prod_id 1400501466: 4.29\n",
            "Actual rating: N/A\n"
          ]
        }
      ],
      "source": [
        "# Use sim_user_user_optimized model to recommend for userId \"A2UOHALGF2X77Q\" and productId \"1400501466\"\n",
        "\n",
        "# Re-train baseline model\n",
        "baseline_sim_options = {'name': 'cosine', 'user_based': True}\n",
        "baseline_model = KNNBasic(k=40, min_k=1, sim_options=baseline_sim_options, verbose=False, random_state=1)\n",
        "baseline_model.fit(trainset)\n",
        "\n",
        "# set user and prod ID\n",
        "user_id = 'A2UOHALGF2X77Q'\n",
        "prod_id = '1400501466'\n",
        "\n",
        "# Use the optimized KNNBasic model\n",
        "optimized_pred = model.predict(user_id, prod_id)\n",
        "\n",
        "# Baseline model prediction\n",
        "baseline_pred = baseline_model.predict(user_id, prod_id)\n",
        "\n",
        "# Print comparison\n",
        "print(f\"Baseline model - Predicted rating for user {user_id} and prod_id {prod_id}: {baseline_pred.est:.2f}\")\n",
        "print(f\"Optimized model - Predicted rating for user {user_id} and prod_id {prod_id}: {optimized_pred.est:.2f}\")\n",
        "print(f\"Actual rating: N/A\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5i-OPprNF2e"
      },
      "source": [
        "**Write your observations here: Our original predictor was 3.4 for A3 user and remained 3.4 after optimizing. This still sharply differs from the actual rating of 5.0 - the predictor for A2 dropped from 5.0 to 4.29 - as we know the model is slightly more tuned it is accruate to say this is a closer approximation, but still needs work and is not very certain.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op_zwO_FnVNH"
      },
      "source": [
        "### **Identifying similar users to a given user (nearest neighbors)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2QsfqhanVNH"
      },
      "source": [
        "We can also find out **similar users to a given user** or its **nearest neighbors** based on this KNNBasic algorithm. Below, we are finding the 5 most similar users to the first user in the list with internal id 0, based on the `msd` distance metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "TbFle7cKmBJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b91172b-462b-4065-962d-0d06e0a2820c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 most similar users to internal id 0 (using MSD): ['A16J281SJ9QXIQ', 'A3CJ7MHAS9IMAM', 'A2L0F2T1DLTNT8', 'AYMD77ITD15PT', 'A21I62TCDL4754']\n"
          ]
        }
      ],
      "source": [
        "# 0 is the inner id of the above user\n",
        "\n",
        "#import check\n",
        "from surprise import KNNBasic\n",
        "\n",
        "# Create KNNBasic model but this time with MSD similarity\n",
        "sim_options_msd = {'name': 'msd', 'user_based': True}\n",
        "model_msd = KNNBasic(k=60, min_k=5, sim_options=sim_options_msd, verbose=False, random_state=1)\n",
        "model_msd.fit(trainset)\n",
        "\n",
        "# Pull the 5 most similar users to our internal id 0\n",
        "similar_users_internal = model_msd.get_neighbors(0, k=5)\n",
        "\n",
        "# Convert internal IDs to raw user IDs for legibility\n",
        "similar_user_ids = [model_msd.trainset.to_raw_uid(iid) for iid in similar_users_internal]\n",
        "\n",
        "# Print results in a clean statement\n",
        "print(f\"5 most similar users to internal id 0 (using MSD): {similar_user_ids}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0NsrX_anVNH"
      },
      "source": [
        "### **Implementing the recommendation algorithm based on optimized KNNBasic model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3ESobDynVNI"
      },
      "source": [
        "Below we will be implementing a function where the input parameters are:\n",
        "\n",
        "- data: A **rating** dataset\n",
        "- user_id: A user id **against which we want the recommendations**\n",
        "- top_n: The **number of products we want to recommend**\n",
        "- algo: the algorithm we want to use **for predicting the ratings**\n",
        "- The output of the function is a **set of top_n items** recommended for the given user_id based on the given algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "vW9V1Tk65HlY"
      },
      "outputs": [],
      "source": [
        "def get_recommendations(data, user_id, top_n, algo):\n",
        "\n",
        "    # Creating an empty list to store the recommended product ids\n",
        "    recommendations = []\n",
        "\n",
        "    # Creating an user item interactions matrix\n",
        "    user_item_interactions_matrix = data.pivot(index = 'user_id', columns = 'prod_id', values = 'rating')\n",
        "\n",
        "    # Extracting those product ids which the user_id has not interacted yet\n",
        "    non_interacted_products = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()\n",
        "\n",
        "    # Looping through each of the product ids which user_id has not interacted yet\n",
        "    for item_id in non_interacted_products:\n",
        "\n",
        "        # Predicting the ratings for those non interacted product ids by this user\n",
        "        est = algo.predict(user_id, item_id).est\n",
        "\n",
        "        # Appending the predicted ratings\n",
        "        recommendations.append((item_id, est))\n",
        "\n",
        "    # Sorting the predicted ratings in descending order\n",
        "    recommendations.sort(key = lambda x: x[1], reverse = True)\n",
        "\n",
        "    return recommendations[:top_n] # Returing top n highest predicted rating products for this user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj_S7kh4nVNI"
      },
      "source": [
        "**Predicting top 5 products for userId = \"A3LDPF5FMB782Z\" with similarity based recommendation system**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "qWbR85mI5Hrk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2025f9b5-3421-4541-86c0-797cf742ac81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 recommendations for user A3LDPF5FMB782Z:\n",
            "Product ID: B000067RT6, Predicted Rating: 5.00\n",
            "Product ID: B000BQ7GW8, Predicted Rating: 5.00\n",
            "Product ID: B001ENW61I, Predicted Rating: 5.00\n",
            "Product ID: B001TH7GUU, Predicted Rating: 5.00\n",
            "Product ID: B001TH7T2U, Predicted Rating: 5.00\n"
          ]
        }
      ],
      "source": [
        "# Making top 5 recommendations for user_id \"A3LDPF5FMB782Z\" with a similarity-based recommendation engine\n",
        "\n",
        "# safe define our optimized function\n",
        "sim_options = {'name': 'cosine', 'user_based': True}\n",
        "sim_user_user_optimized = KNNBasic(k=60, min_k=5, sim_options=sim_options, verbose=False, random_state=1)\n",
        "sim_user_user_optimized.fit(trainset)\n",
        "\n",
        "#start with our above defined function\n",
        "\n",
        "def get_recommendations(data, user_id, top_n, algo):\n",
        "    # Create an empty list to store the recommended product IDs\n",
        "    recommendations = []\n",
        "\n",
        "    # Create user-item interactions matrix\n",
        "    user_item_interactions_matrix = data.pivot(index='user_id', columns='prod_id', values='rating')\n",
        "\n",
        "    # Extract product IDs the user has not interacted with\n",
        "    non_interacted_products = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()\n",
        "\n",
        "    # Predict ratings for non-interacted products\n",
        "    for prod_id in non_interacted_products:\n",
        "        est = algo.predict(user_id, prod_id).est\n",
        "        recommendations.append((prod_id, est))\n",
        "\n",
        "    # Sort by predicted rating in descending order\n",
        "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return recommendations[:top_n]\n",
        "\n",
        "# Now we can grab the\n",
        "# top 5 recommendations for user A3LDPF5FMB782Z using optimized model\n",
        "# let's set our user id and top n params as well as sim system and df\n",
        "user_id = 'A3LDPF5FMB782Z'\n",
        "top_n = 5\n",
        "recommendations = get_recommendations(df_final, user_id, top_n, sim_user_user_optimized)\n",
        "\n",
        "# Let's print the results in a clean output using a for loop\n",
        "print(f\"Top {top_n} recommendations for user {user_id}:\")\n",
        "for prod_id, rating in recommendations:\n",
        "    print(f\"Product ID: {prod_id}, Predicted Rating: {rating:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "b5WfIX0Z6_q2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ab1fef-5464-44f8-d444-9cf589ce0c88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 recommendations for user A3LDPF5FMB782Z:\n",
            "      prod_id  predicted_ratings\n",
            "0  B000067RT6                  5\n",
            "1  B000BQ7GW8                  5\n",
            "2  B001ENW61I                  5\n",
            "3  B001TH7GUU                  5\n",
            "4  B001TH7T2U                  5\n"
          ]
        }
      ],
      "source": [
        "# Building the dataframe for above recommendations with columns \"prod_id\" and \"predicted_ratings\"\n",
        "\n",
        "# Build DataFrame with columns prod_id and predicted_ratings as requested\n",
        "recommendations_df = pd.DataFrame(recommendations, columns=['prod_id', 'predicted_ratings'])\n",
        "\n",
        "# Print DataFrame to check\n",
        "print(f\"Top {top_n} recommendations for user {user_id}:\")\n",
        "print(recommendations_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgbzJKk7Tsnr"
      },
      "source": [
        "### **Item-Item Similarity-based Collaborative Filtering Recommendation System**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTJu_2hcTsnr"
      },
      "source": [
        "* Above we have seen **similarity-based collaborative filtering** where similarity is calculated **between users**. Now let us look into similarity-based collaborative filtering where similarity is seen **between items**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "W5RMcdzjTsns",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ef95ff-5722-40fe-f31c-3e3ecca40c64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision:  0.836\n",
            "Recall:  0.876\n",
            "F_1 score:  0.856\n"
          ]
        }
      ],
      "source": [
        "# Declaring the similarity options\n",
        "#item-item\n",
        "sim_options = {'name': 'cosine', 'user_based': False}\n",
        "\n",
        "# KNN algorithm is used to find desired similar items. Use random_state=1\n",
        "item_item_model = KNNBasic(k=60, min_k=5, sim_options=sim_options, verbose=False, random_state=1)\n",
        "\n",
        "# Train the algorithm on the trainset, and predict ratings for the test set\n",
        "item_item_model.fit(trainset)\n",
        "\n",
        "# Let us compute precision@k, recall@k, and f_1 score with k = 10\n",
        "# Compute precision@k, recall@k, and F1-score@k with k=10\n",
        "def precision_recall_at_k(model, k=10, threshold=3.5):\n",
        "#i've notated this 100 times now so you know I know how this works\n",
        "    \"\"\"\n",
        "    Return precision and recall\n",
        "    at k metrics for each user\n",
        "    \"\"\"\n",
        "    user_est_true = defaultdict(list)\n",
        "    predictions = model.test(testset)\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
        "                              for (est, true_r) in user_ratings[:k])\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
        "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
        "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
        "    print('Precision: ', precision)\n",
        "    print('Recall: ', recall)\n",
        "    print('F_1 score: ', round((2 * precision * recall) / (precision + recall), 3) if (precision + recall) != 0 else 0)\n",
        "\n",
        "# Evaluate the item-item model as result\n",
        "precision_recall_at_k(item_item_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni9LoeUVTsns"
      },
      "source": [
        "**Write your observations here: The optimized user-user model’s superior performance indicates user similarities are stronger in this dataset than this untuned item-item model which has less precision, recall, and harmonics than the optimized model previously.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFbcDQmxTsns"
      },
      "source": [
        "Let's now **predict a rating for a user with `userId = A3LDPF5FMB782Z` and `prod_Id = 1400501466`** as shown below. Here the user has already interacted or watched the product with productId \"1400501466\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "JsF-aaWYTsns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ef998e-d227-4437-f815-3ac5b09a8930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Item-item model - Predicted rating for user A3LDPF5FMB782Z and prod_id 1400501466: 4.27\n",
            "Actual rating: 5.00\n"
          ]
        }
      ],
      "source": [
        "# Predicting rating for a sample user with an interacted product\n",
        "\n",
        "# set params\n",
        "user_id = 'A3LDPF5FMB782Z'\n",
        "prod_id = '1400501466'\n",
        "\n",
        "# Retrieve actual rating from df_final to compare\n",
        "actual_rating = df_final[(df_final['user_id'] == user_id) & (df_final['prod_id'] == prod_id)]['rating']\n",
        "\n",
        "# Predict rating using item-item KNNBasic model\n",
        "predicted_rating = item_item_model.predict(user_id, prod_id)\n",
        "\n",
        "# Print results\n",
        "print(f\"Item-item model - Predicted rating for user {user_id} and prod_id {prod_id}: {predicted_rating.est:.2f}\")\n",
        "print(f\"Actual rating: {actual_rating.iloc[0]:.2f}\" if not actual_rating.empty else f\"No actual rating exists for user {user_id} and prod_id {prod_id}\")\n",
        "#expanding good practice for if although we checked for missing data at start"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h0OyDMFTsns"
      },
      "source": [
        "**Write your observations here: Although we know the model is technically less precise and has worse recall than the optimized model item-item comparison seems to handle the data sparsity better, driving our result to a 0.73 difference as opposed to the previous 1.6 - this data could be circumstantial and more tuning and analysis is still needed.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqKGZoAtTsns"
      },
      "source": [
        "Below we are **predicting rating for the `userId = A2UOHALGF2X77Q` and `prod_id = 1400501466`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "5yILOxXRTsns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df263ab9-3316-410f-b143-a79cb1cc3269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Item-item model - Predicted rating for user A2UOHALGF2X77Q and prod_id 1400501466: 4.29\n",
            "Actual rating: None (user has not interacted with this product)\n"
          ]
        }
      ],
      "source": [
        "# Predicting rating for a sample user with a non interacted product\n",
        "\n",
        "# set params\n",
        "user_id = 'A2UOHALGF2X77Q'\n",
        "prod_id = '1400501466'\n",
        "\n",
        "# Predict rating using item-item KNNBasic model\n",
        "predicted_rating = item_item_model.predict(user_id, prod_id)\n",
        "\n",
        "# Print results\n",
        "print(f\"Item-item model - Predicted rating for user {user_id} and prod_id {prod_id}: {predicted_rating.est:.2f}\")\n",
        "print(f\"Actual rating: None (user has not interacted with this product)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDKaAveJTsns"
      },
      "source": [
        "**Write your observations here: Our prediction matches the global mean which is a coincidence or highly suggestive of data sparsity or a lack of relevant items, it is above 3.5 and would be recommended.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meSvpNLj_EjD"
      },
      "source": [
        "### **Hyperparameter tuning the item-item similarity-based model**\n",
        "- Use the following values for the param_grid and tune the model.\n",
        "  - 'k': [10, 20, 30]\n",
        "  - 'min_k': [3, 6, 9]\n",
        "  - 'sim_options': {'name': ['msd', 'cosine']\n",
        "  - 'user_based': [False]\n",
        "- Use GridSearchCV() to tune the model using the 'rmse' measure\n",
        "- Print the best score and best parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "f5bcZ3HgTsnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a04749e-8cb9-4084-f84e-1967afd713c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE score: 0.975\n",
            "Best parameters:\n",
            "  k: 20\n",
            "  min_k: 6\n",
            "  sim_options: {'name': 'msd', 'user_based': False}\n"
          ]
        }
      ],
      "source": [
        "# Setting up parameter grid to tune the hyperparameters\n",
        "# as we did before and as above\n",
        "param_grid = {\n",
        "    'k': [10, 20, 30],\n",
        "    'min_k': [3, 6, 9],\n",
        "    'sim_options': {\n",
        "        'name': ['msd', 'cosine'],\n",
        "        'user_based': [False]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Performing 3-fold cross validation to tune the hyperparameters\n",
        "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
        "\n",
        "# Fitting the data\n",
        "gs.fit(data)\n",
        "\n",
        "# Find the best RMSE score\n",
        "best_rmse = gs.best_score['rmse']\n",
        "\n",
        "# Find the combination of parameters that gave the best RMSE score\n",
        "best_params = gs.best_params['rmse']\n",
        "\n",
        "# Print results for clean view\n",
        "print(f\"Best RMSE score: {best_rmse:.3f}\")\n",
        "print(\"Best parameters:\")\n",
        "print(f\"  k: {best_params['k']}\")\n",
        "print(f\"  min_k: {best_params['min_k']}\")\n",
        "print(f\"  sim_options: {best_params['sim_options']}\")\n",
        "\n",
        "#takes a bit\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1psOlx6zTsnt"
      },
      "source": [
        "Once the **grid search** is complete, we can get the **optimal values for each of those hyperparameters as shown above.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrSTaQemTsnt"
      },
      "source": [
        "Now let's build the **final model** by using **tuned values of the hyperparameters** which we received by using grid search cross-validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOS9Dwnd_LN6"
      },
      "source": [
        "### **Use the best parameters from GridSearchCV to build the optimized item-item similarity-based model. Compare the performance of the optimized model with the baseline model.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "dSeiM1qeTsnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b37097d-8d8c-4ef8-8fa0-ea94b7c5fb06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Item-Item Model Performance:\n",
            "Precision:  0.839\n",
            "Recall:  0.88\n",
            "F_1 score:  0.859\n",
            "RMSE:  0.958\n",
            "\n",
            "Baseline Item-Item Model Performance:\n",
            "Precision:  0.836\n",
            "Recall:  0.876\n",
            "F_1 score:  0.856\n",
            "RMSE:  0.961\n"
          ]
        }
      ],
      "source": [
        "# Using the optimal similarity measure for item-item based collaborative filtering\n",
        "\n",
        "# import check\n",
        "from surprise import KNNBasic\n",
        "from surprise.accuracy import rmse\n",
        "from collections import defaultdict\n",
        "\n",
        "# Use optimal similarity measure as above\n",
        "sim_options = {'name': 'msd', 'user_based': False}\n",
        "\n",
        "# Creating an instance of KNNBasic with optimal hyperparameter values\n",
        "optimized_item_item_model = KNNBasic(k=20, min_k=6, sim_options=sim_options, verbose=False, random_state=1)\n",
        "\n",
        "# Training the algorithm on the trainset\n",
        "optimized_item_item_model.fit(trainset)\n",
        "\n",
        "# Let us compute precision@k and recall@k, f1_score and RMSE\n",
        "def precision_recall_at_k(model, k=10, threshold=3.5):\n",
        "    \"\"\"\n",
        "    Return precision, recall, and F1-score at k metrics for each user\n",
        "    \"\"\"\n",
        "    user_est_true = defaultdict(list)\n",
        "    predictions = model.test(testset)\n",
        "\n",
        "    # Compute RMSE\n",
        "    rmse_score = rmse(predictions, verbose=False)\n",
        "\n",
        "    # Compute precision and recall\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
        "                              for (est, true_r) in user_ratings[:k])\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
        "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
        "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
        "    f1_score = round((2 * precision * recall) / (precision + recall), 3) if (precision + recall) != 0 else 0\n",
        "\n",
        "    print('Precision: ', precision)\n",
        "    print('Recall: ', recall)\n",
        "    print('F_1 score: ', f1_score)\n",
        "    print('RMSE: ', round(rmse_score, 3))\n",
        "\n",
        "# Evaluate the optimized item-item model\n",
        "print(\"Optimized Item-Item Model Performance:\")\n",
        "precision_recall_at_k(optimized_item_item_model)\n",
        "\n",
        "# let's appendn this with a direct comparison to baseline performance to observe\n",
        "baseline_sim_options = {'name': 'cosine', 'user_based': False}\n",
        "baseline_item_item_model = KNNBasic(k=60, min_k=5, sim_options=baseline_sim_options, verbose=False, random_state=1)\n",
        "baseline_item_item_model.fit(trainset)\n",
        "print(\"\\nBaseline Item-Item Model Performance:\")\n",
        "precision_recall_at_k(baseline_item_item_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCXKnMI8Tsnt"
      },
      "source": [
        "**Write your observations here: We increased Precision by 0.3%, we increased recall by 0.4%, and we raised the f-score 0.003 - however, the RMSE score lowered. This RMSE is still behind the user-user optimized value indicating users still have a stronger sway on data than items. **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbcj_H94Tsnt"
      },
      "source": [
        "### **Steps:**\n",
        "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
        "- **Predict rating for `userId=\"A2UOHALGF2X77Q\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
        "- **Compare the output with the output from the baseline model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "gIBRRvdoTsnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf0de94-3d21-4f28-c73f-584b5bba5c19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User A3LDPF5FMB782Z and prod_id 1400501466:\n",
            "Baseline item-item model - Predicted rating: 4.27\n",
            "Optimized item-item model - Predicted rating: 4.71\n",
            "Actual rating: 5.00\n"
          ]
        }
      ],
      "source": [
        "# Use sim_item_item_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId \"1400501466\"\n",
        "\n",
        "#import check\n",
        "import pandas as pd\n",
        "from surprise import KNNBasic\n",
        "\n",
        "# Re-train check\n",
        "baseline_sim_options = {'name': 'cosine', 'user_based': False}\n",
        "baseline_item_item_model = KNNBasic(k=60, min_k=5, sim_options=baseline_sim_options, verbose=False, random_state=1)\n",
        "baseline_item_item_model.fit(trainset)\n",
        "\n",
        "# params\n",
        "user_id1 = 'A3LDPF5FMB782Z'\n",
        "prod_id = '1400501466'\n",
        "\n",
        "# Retrieve actual rating from df_final\n",
        "actual_rating = df_final[(df_final['user_id'] == user_id1) & (df_final['prod_id'] == prod_id)]['rating']\n",
        "\n",
        "# Baseline model prediction\n",
        "baseline_pred1 = baseline_item_item_model.predict(user_id1, prod_id)\n",
        "\n",
        "# Optimized model prediction\n",
        "optimized_pred1 = optimized_item_item_model.predict(user_id1, prod_id)\n",
        "\n",
        "# Print results in clean statement\n",
        "print(f\"\\nUser {user_id1} and prod_id {prod_id}:\")\n",
        "print(f\"Baseline item-item model - Predicted rating: {baseline_pred1.est:.2f}\")\n",
        "print(f\"Optimized item-item model - Predicted rating: {optimized_pred1.est:.2f}\")\n",
        "print(f\"Actual rating: {actual_rating.iloc[0]:.2f}\" if not actual_rating.empty else f\"No actual rating exists\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "f2wDOZTYW7bP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e4472c0-3be5-4573-bef4-02589476a527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User A2UOHALGF2X77Q and prod_id 1400501466:\n",
            "Baseline item-item model - Predicted rating: 4.29\n",
            "Optimized item-item model - Predicted rating: 4.29\n",
            "Actual rating: None (user has not interacted with this product)\n"
          ]
        }
      ],
      "source": [
        "# Use sim_item_item_optimized model to recommend for userId \"A2UOHALGF2X77Q\" and productId \"1400501466\"\n",
        "\n",
        "# params\n",
        "user_id2 = 'A2UOHALGF2X77Q'\n",
        "\n",
        "# Baseline model prediction\n",
        "baseline_pred2 = baseline_item_item_model.predict(user_id2, prod_id)\n",
        "\n",
        "# Optimized model prediction\n",
        "optimized_pred2 = optimized_item_item_model.predict(user_id2, prod_id)\n",
        "\n",
        "# Print results for A2UOHALGF2X77Q\n",
        "print(f\"\\nUser {user_id2} and prod_id {prod_id}:\")\n",
        "print(f\"Baseline item-item model - Predicted rating: {baseline_pred2.est:.2f}\")\n",
        "print(f\"Optimized item-item model - Predicted rating: {optimized_pred2.est:.2f}\")\n",
        "print(f\"Actual rating: None (user has not interacted with this product)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb26WmA0W7bP"
      },
      "source": [
        "**Write your observations here: The improved rating of 4.71 is our closest yet to actual rating and a 60% reduction in error from the baseline. We see as well that the other predictor again matches the global mean due to sparsity or lack of near comparison - the fact that this didn't change with tuning makes this even more so the case for this specific product.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDlNB7tnTsnu"
      },
      "source": [
        "### **Identifying similar items to a given item (nearest neighbors)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLdDiFA6Tsnu"
      },
      "source": [
        "We can also find out **similar items** to a given item or its nearest neighbors based on this **KNNBasic algorithm**. Below we are finding the 5 most similar items to the item with internal id 0 based on the `msd` distance metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "ZRJS4oDFTsnu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d42fec-df25-4c9d-b41f-a175d9930ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 most similar items to internal id 0 (using MSD): ['B008X9Z3UC', 'B003ZSHKJ8', 'B003LSTD38', 'B005EOWBKE', 'B004IZN3WU']\n"
          ]
        }
      ],
      "source": [
        "# model confirm\n",
        "sim_options_msd = {'name': 'msd', 'user_based': False}\n",
        "item_item_model_msd = KNNBasic(k=20, min_k=6, sim_options=sim_options_msd, verbose=False, random_state=1)\n",
        "item_item_model_msd.fit(trainset)\n",
        "\n",
        "# Get 5 most similar items to internal id 0\n",
        "similar_items_internal = item_item_model_msd.get_neighbors(0, k=5)\n",
        "\n",
        "# Convert internal IDs to raw product IDs\n",
        "similar_item_ids = [item_item_model_msd.trainset.to_raw_iid(iid) for iid in similar_items_internal]\n",
        "\n",
        "# Print results\n",
        "print(f\"5 most similar items to internal id 0 (using MSD): {similar_item_ids}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPvcS_OlW7bP"
      },
      "source": [
        "**Predicting top 5 products for userId = \"A1A5KUIIIHFF4U\" with similarity based recommendation system.**\n",
        "\n",
        "**Hint:** Use the get_recommendations() function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "rzoEbuZFTsnu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebea5fa1-6796-4a6b-c723-4c7725cee7ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 recommendations for user A1A5KUIIIHFF4U:\n",
            "Product ID: 1400532655, Predicted Rating: 4.29\n",
            "Product ID: 1400599997, Predicted Rating: 4.29\n",
            "Product ID: 9983891212, Predicted Rating: 4.29\n",
            "Product ID: B00000DM9W, Predicted Rating: 4.29\n",
            "Product ID: B00000J1V5, Predicted Rating: 4.29\n"
          ]
        }
      ],
      "source": [
        "# Making top 5 recommendations for user_id A1A5KUIIIHFF4U with similarity-based recommendation engine.\n",
        "\n",
        "def get_recommendations(data, user_id, top_n, algo):\n",
        "    # Create an empty list to store the recommended product IDs\n",
        "    recommendations = []\n",
        "\n",
        "    # Create user-item interactions matrix\n",
        "    user_item_interactions_matrix = data.pivot(index='user_id', columns='prod_id', values='rating')\n",
        "\n",
        "    # Extract product IDs the user has not interacted with\n",
        "    non_interacted_products = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()\n",
        "\n",
        "    # Predict ratings for non-interacted products\n",
        "    for prod_id in non_interacted_products:\n",
        "        est = algo.predict(user_id, prod_id).est\n",
        "        recommendations.append((prod_id, est))\n",
        "\n",
        "    # Sort by predicted rating in descending order\n",
        "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return recommendations[:top_n]\n",
        "\n",
        "# Get top 5 recommendations and params\n",
        "user_id = 'A1A5KUIIIHFF4U'\n",
        "top_n = 5\n",
        "recommendations = get_recommendations(df_final, user_id, top_n, optimized_item_item_model)\n",
        "\n",
        "# Print results\n",
        "print(f\"Top {top_n} recommendations for user {user_id}:\")\n",
        "for prod_id, rating in recommendations:\n",
        "    print(f\"Product ID: {prod_id}, Predicted Rating: {rating:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "_kXVTiysTsnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7afdf204-1ca1-41dd-b8e7-520d8c9bb1b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 recommendations for user A1A5KUIIIHFF4U:\n",
            "      prod_id  predicted_ratings\n",
            "0  1400532655           4.292024\n",
            "1  1400599997           4.292024\n",
            "2  9983891212           4.292024\n",
            "3  B00000DM9W           4.292024\n",
            "4  B00000J1V5           4.292024\n"
          ]
        }
      ],
      "source": [
        "# Building the dataframe for above recommendations with columns \"prod_id\" and \"predicted_ratings\"\n",
        "recommendations_df = pd.DataFrame(recommendations, columns=['prod_id', 'predicted_ratings'])\n",
        "\n",
        "# Print DataFrame\n",
        "print(f\"Top {top_n} recommendations for user {user_id}:\")\n",
        "print(recommendations_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHzmYvs0Tsnv"
      },
      "source": [
        "Now as we have seen **similarity-based collaborative filtering algorithms**, let us now get into **model-based collaborative filtering algorithms**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKgJpSA9vOOL"
      },
      "source": [
        "### **Model 3: Model-Based Collaborative Filtering - Matrix Factorization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF6ZGyqhCAob"
      },
      "source": [
        "Model-based Collaborative Filtering is a **personalized recommendation system**, the recommendations are based on the past behavior of the user and it is not dependent on any additional information. We use **latent features** to find recommendations for each user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4Otha8ovOOL"
      },
      "source": [
        "### Singular Value Decomposition (SVD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sGl3QkLvOOL"
      },
      "source": [
        "SVD is used to **compute the latent features** from the **user-item matrix**. But SVD does not work when we **miss values** in the **user-item matrix**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "07-2PT5Ssjqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "087c3ac7-6b61-4059-e581-41a0783b0c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVD Model Performance:\n",
            "Precision:  0.853\n",
            "Recall:  0.88\n",
            "F_1 score:  0.866\n",
            "RMSE:  0.888\n"
          ]
        }
      ],
      "source": [
        "# Using SVD matrix factorization. Use random_state = 1\n",
        "svd_model = SVD(random_state=1)\n",
        "\n",
        "# Training the algorithm on the trainset\n",
        "svd_model.fit(trainset)\n",
        "\n",
        "# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE\n",
        "def precision_recall_at_k(model, k=10, threshold=3.5):\n",
        "    \"\"\"Return precision, recall, and F1-score at k metrics for each user\"\"\"\n",
        "    user_est_true = defaultdict(list)\n",
        "    predictions = model.test(testset)\n",
        "\n",
        "    # Compute RMSE\n",
        "    rmse_score = rmse(predictions, verbose=False)\n",
        "\n",
        "    # Compute precision and recall\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
        "                              for (est, true_r) in user_ratings[:k])\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
        "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
        "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
        "    f1_score = round((2 * precision * recall) / (precision + recall), 3) if (precision + recall) != 0 else 0\n",
        "\n",
        "    print('Precision: ', precision)\n",
        "    print('Recall: ', recall)\n",
        "    print('F_1 score: ', f1_score)\n",
        "    print('RMSE: ', round(rmse_score, 3))\n",
        "\n",
        "# Evaluate the SVD model\n",
        "print(\"SVD Model Performance:\")\n",
        "precision_recall_at_k(svd_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ6fTuCDnVNL"
      },
      "source": [
        "**Write your observations here:\n",
        "For precision it is only below the baseline user-user model.\n",
        "Recall matches optimized items but is below optimized users.\n",
        "F_1 score is only beaten out by optimized users.\n",
        "The highest RMSE yet and at scaled significance performs better.\n",
        "\n",
        "Incorporating latent factors seems to improve accuracy.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAogg-noW7bQ"
      },
      "source": [
        "**Let's now predict the rating for a user with `userId = \"A3LDPF5FMB782Z\"` and `prod_id = \"1400501466`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "yWIhfdxXsjqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "976c9304-fbff-4752-df7e-cf5dcb49e4a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVD model - Predicted rating for user A3LDPF5FMB782Z and prod_id 1400501466: 4.08\n",
            "Actual rating: 5.00\n"
          ]
        }
      ],
      "source": [
        "# Making prediction\n",
        "# params\n",
        "user_id = 'A3LDPF5FMB782Z'\n",
        "prod_id = '1400501466'\n",
        "\n",
        "# Retrieve actual rating from df_final\n",
        "actual_rating = df_final[(df_final['user_id'] == user_id) & (df_final['prod_id'] == prod_id)]['rating']\n",
        "\n",
        "# Predict rating using SVD model\n",
        "predicted_rating = svd_model.predict(user_id, prod_id)\n",
        "\n",
        "# Print results\n",
        "print(f\"SVD model - Predicted rating for user {user_id} and prod_id {prod_id}: {predicted_rating.est:.2f}\")\n",
        "print(f\"Actual rating: {actual_rating.iloc[0]:.2f}\" if not actual_rating.empty else f\"No actual rating exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIjzqDY5nVNM"
      },
      "source": [
        "**Write your observations here: The prediciton error is lower than all models except for optimized item-item which is more accurate in this instance. SVD works better than user-user models but not as well as optimized item-item for this product.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1aYxVeMnVNM"
      },
      "source": [
        "**Below we are predicting rating for the `userId = \"A2UOHALGF2X77Q\"` and `productId = \"1400501466\"`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "APm-uMSvcAMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e663aa19-eeb3-458d-d2fe-9e3794ff53b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVD model - Predicted rating for user A2UOHALGF2X77Q and prod_id 1400501466: 4.16\n",
            "Actual rating: None (user has not interacted with this product)\n"
          ]
        }
      ],
      "source": [
        "# set params\n",
        "user_id = 'A2UOHALGF2X77Q'\n",
        "prod_id = '1400501466'\n",
        "\n",
        "# Predict rating using SVD model\n",
        "predicted_rating = svd_model.predict(user_id, prod_id)\n",
        "\n",
        "# Print results\n",
        "print(f\"SVD model - Predicted rating for user {user_id} and prod_id {prod_id}: {predicted_rating.est:.2f}\")\n",
        "print(f\"Actual rating: None (user has not interacted with this product)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEL6dy3wnVNM"
      },
      "source": [
        "**Write your observations here: Slightly below our global mean this time suggesting the result isn't directly from sparsity or a more conservative prediction. Likely an under prediction from SVD limitations based on our other data points.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x13Eb9Owvpcw"
      },
      "source": [
        "### **Improving Matrix Factorization based recommendation system by tuning its hyperparameters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQcDPhhcnVNN"
      },
      "source": [
        "Below we will be tuning only three hyperparameters:\n",
        "- **n_epochs**: The number of iterations of the SGD algorithm.\n",
        "- **lr_all**: The learning rate for all parameters.\n",
        "- **reg_all**: The regularization term for all parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "4bM81V_hvtwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77370321-64c6-4855-c9e4-0a5cf01ce648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best RMSE score: 0.898\n",
            "Best parameters:\n",
            "  n_epochs: 30\n",
            "  lr_all: 0.01\n",
            "  reg_all: 0.2\n"
          ]
        }
      ],
      "source": [
        "# Set the parameter space to tune\n",
        "param_grid = {\n",
        "    'n_epochs': [10, 20, 30],\n",
        "    'lr_all': [0.002, 0.005, 0.01],\n",
        "    'reg_all': [0.02, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# Perform 3-fold gridsearch cross-validation\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
        "\n",
        "# Fit the data\n",
        "gs.fit(data)\n",
        "\n",
        "# Best RMSE score\n",
        "best_rmse = gs.best_score['rmse']\n",
        "\n",
        "# Combination of parameters that gave the best RMSE score\n",
        "best_params = gs.best_params['rmse']\n",
        "\n",
        "# Print results\n",
        "print(f\"Best RMSE score: {best_rmse:.3f}\")\n",
        "print(\"Best parameters:\")\n",
        "print(f\"  n_epochs: {best_params['n_epochs']}\")\n",
        "print(f\"  lr_all: {best_params['lr_all']}\")\n",
        "print(f\"  reg_all: {best_params['reg_all']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzY78HsrnVNO"
      },
      "source": [
        "Now, we will **the build final model** by using **tuned values** of the hyperparameters, which we received using grid search cross-validation above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "TA_7xe-nnhuu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "587036c4-f688-46f5-9483-dc9bc90b64a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized SVD Model Performance:\n",
            "Precision:  0.853\n",
            "Recall:  0.874\n",
            "F_1 score:  0.863\n",
            "RMSE:  0.881\n"
          ]
        }
      ],
      "source": [
        "# Build the optimized SVD model using optimal hyperparameter search. Use random_state=1\n",
        "optimized_svd_model = SVD(n_epochs=best_params['n_epochs'], lr_all=best_params['lr_all'], reg_all=best_params['reg_all'], random_state=1)\n",
        "\n",
        "# Train the algorithm on the trainset\n",
        "optimized_svd_model.fit(trainset)\n",
        "\n",
        "# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE\n",
        "def precision_recall_at_k(model, k=10, threshold=3.5):\n",
        "    \"\"\"\n",
        "    Return precision, recall, and F1-score at k metrics for each user\n",
        "    \"\"\"\n",
        "    user_est_true = defaultdict(list)\n",
        "    predictions = model.test(testset)\n",
        "\n",
        "    # Compute RMSE\n",
        "    rmse_score = rmse(predictions, verbose=False)\n",
        "\n",
        "    # Compute precision and recall\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
        "                              for (est, true_r) in user_ratings[:k])\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
        "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
        "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
        "    f1_score = round((2 * precision * recall) / (precision + recall), 3) if (precision + recall) != 0 else 0\n",
        "\n",
        "    print('Precision: ', precision)\n",
        "    print('Recall: ', recall)\n",
        "    print('F_1 score: ', f1_score)\n",
        "    print('RMSE: ', round(rmse_score, 3))\n",
        "\n",
        "# Evaluate the optimized SVD model\n",
        "print(\"Optimized SVD Model Performance:\")\n",
        "precision_recall_at_k(optimized_svd_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HJvPsjITsny"
      },
      "source": [
        "**Write your observations here: The RMSE is improved over the baseline and other models. Precision is only below baseline user to user. Recall did not improve from baseline or optimized user-user. F_1 score is also below baseline and user to user. Overall we see an increase in accuracy from SVD optimized but only in that factor.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjvOEW9IW7bQ"
      },
      "source": [
        "### **Steps:**\n",
        "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
        "- **Predict rating for `userId=\"A2UOHALGF2X77Q\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
        "- **Compare the output with the output from the baseline model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "hD10e7sBW7bQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab42cfa0-36bc-4263-ee98-e4c0b16a6052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized SVD model - Predicted rating for user A3LDPF5FMB782Z and prod_id 1400501466: 4.24\n",
            "Actual rating: 5.00\n"
          ]
        }
      ],
      "source": [
        "# Use svd_algo_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId \"1400501466\"\n",
        "# set params\n",
        "user_id = 'A3LDPF5FMB782Z'\n",
        "prod_id = '1400501466'\n",
        "\n",
        "# Retrieve actual rating from df_final\n",
        "actual_rating = df_final[(df_final['user_id'] == user_id) & (df_final['prod_id'] == prod_id)]['rating']\n",
        "\n",
        "# Predict rating using optimized SVD model\n",
        "predicted_rating = optimized_svd_model.predict(user_id, prod_id)\n",
        "\n",
        "# Print results\n",
        "print(f\"Optimized SVD model - Predicted rating for user {user_id} and prod_id {prod_id}: {predicted_rating.est:.2f}\")\n",
        "print(f\"Actual rating: {actual_rating.iloc[0]:.2f}\" if not actual_rating.empty else f\"No actual rating exists\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "OKSRcFEzW7bQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16364253-f005-49c9-ece9-b86a98c827b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized SVD model - Predicted rating for user A2UOHALGF2X77Q and prod_id 1400501466: 4.10\n",
            "Actual rating: None (user has not interacted with this product)\n"
          ]
        }
      ],
      "source": [
        "# Use svd_algo_optimized model to recommend for userId \"A2UOHALGF2X77Q\" and productId \"1400501466\"\n",
        "# set params\n",
        "user_id = 'A2UOHALGF2X77Q'\n",
        "prod_id = '1400501466'\n",
        "\n",
        "# Predict rating using optimized SVD model\n",
        "predicted_rating = optimized_svd_model.predict(user_id, prod_id)\n",
        "\n",
        "# Print results\n",
        "print(f\"Optimized SVD model - Predicted rating for user {user_id} and prod_id {prod_id}: {predicted_rating.est:.2f}\")\n",
        "print(f\"Actual rating: None (user has not interacted with this product)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnwPwgjB8DwS"
      },
      "source": [
        "### **Conclusion and Recommendations**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuqnifw9NF2p"
      },
      "source": [
        "**Write your conclusion and recommendations here**\n",
        "\n",
        "Let's pull together all our results to make an apt comparison, I've been recording them on a separate excel sheet but we can also do this with code.\n",
        "\n",
        "Model Performance Comparison\n",
        "A3LDPF5FMB782Z (prod_id=1400501466, actual=5.00):\n",
        "// Baseline User-User: 3.40 (error=1.60)\n",
        "// Optimized User-User: 3.40 (error=1.60)\n",
        "// Baseline Item-Item: 4.27 (error=0.73)\n",
        "// Optimized Item-Item: 4.71 (error=0.29)\n",
        "// Baseline SVD: 4.08 (error=0.92)\n",
        "// Optimized SVD: 4.24 (error=0.76)\n",
        "\n",
        "Observations: The optimized item-item model surpasses all other metrics in this prediction instance, reducing error by around 82% vs. user-user. Optimized SVD improves over baseline SVD (18% error reduction) but lags behind item-item.\n",
        "\n",
        "A2UOHALGF2X77Q (prod_id=1400501466, non-interacted):\n",
        "Baseline User-User: 4.29\n",
        "Optimized User-User: 4.29\n",
        "Baseline Item-Item: 4.29\n",
        "Optimized Item-Item: 4.29\n",
        "Baseline SVD: 4.16\n",
        "Optimized SVD: 4.10\n",
        "\n",
        "Observations: All of the models predict relatively close to the global mean (4.29) for non-interacted items, with optimized SVD slightly lower (4.10) which means there is some sparsity which doesn't let us differentiate much.\n",
        "\n",
        "Overall:\n",
        "\n",
        "I am going to recommend the Optimized SVD model. It has the best RMSE score at 0.881 showing the highest relationship in prediciton accuracy over KNN-based models alongside a balanced F1 score which will better serve the massive number of products that Amazon has and sells.\n",
        "\n",
        "The risk of using item-item optimization is that although it may better identify niche products it will more often recommend irrelevant items which is more harmful in an online shopping environment to overall margins.\n",
        "\n",
        "The risk of using the user-user model is that although it has the best recall and includes the most relevant items it produces a high rate of error that nullifies most downstream predictions.\n",
        "\n",
        "Overall our results identify and point to a sparsity challenge that should be addressed by Amazon as best as possible to provide more data and better improve model performance and analysis.\n",
        "\n",
        "A brief look online shows that Amazon relies on its recommendation system for nearly 1/3rd of its total sales making the recommendation of niche electronics a considerable pain point.\n",
        "\n",
        "A hybrid approach could be implemented through SVD and item-item analysis to create stronger results but it will need to be heavily tested and monitored. It could also be specifically implemented in the sector of niche electronics but this requires a larger understanding of inventory definition and grouping.\n",
        "\n",
        "Overall an increase of data access (as in most cases) can help solve this problem so any data integrations that can access real time inventory especially on newly released products would help. The dataset could also be deepened to show relationships between product brands as companies often iteratively release new products without much marginal difference every year leading to our runaway niche recommendation problem - in reality this is mostly a naming convention for products not customer utility distinction and reworking the data to reflect this could help strengthen our results and reduce error from seeming sparsity."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}